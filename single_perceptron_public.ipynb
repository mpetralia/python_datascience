{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single Layer Perceptron\n",
    "\n",
    "Megan Petralia\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of a Perceptron Network \n",
    "\n",
    "Comments added throughout code to help describe algorithm as well as output at each iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up\n",
    "Input Requirements: \n",
    "User will provide:\n",
    "\n",
    "- Network configuration information\n",
    "\n",
    "- Learning rate\n",
    "\n",
    "- Location of training and testing data sets that will be passed to a function later in the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1:\n",
    "### Get inputs, and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get these values from user\n",
    "\n",
    "Training_Location = input(\"File Location for training dataset\")\n",
    "LearningRate = float(input(\"Learning Rate\"))\n",
    "bias = float(input(\"Bias value\"))\n",
    "weight1_input = float(input(\"Initial value for weight 1\"))\n",
    "weight2_input = float(input(\"Initial value for weight 2\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in a linear separable dataset\n",
    "data = pd.read_csv(Training_Location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   x1      500 non-null    float64\n",
      " 1   x2      500 non-null    float64\n",
      " 2   y       499 non-null    object \n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 11.8+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.2418</td>\n",
       "      <td>-0.8484</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.6919</td>\n",
       "      <td>1.0404</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.3198</td>\n",
       "      <td>0.6226</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       x1      x2  y\n",
       "0 -0.2418 -0.8484  a\n",
       "1 -1.6919  1.0404  a\n",
       "2 -0.3198  0.6226  a"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps 2 - 4:\n",
    "### Activation\n",
    "### Computation of Actual Result\n",
    "### Continuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With threshold function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1\n",
      "New weights are:  -860.8456999999997  ,  -219.03399999999993\n",
      "49%  accuracy\n",
      "Iteration  2\n",
      "New weights are:  -813.92  ,  -335.0471999999998\n",
      "93%  accuracy\n",
      "Iteration  3\n",
      "New weights are:  -796.1083  ,  -358.6017999999998\n",
      "98%  accuracy\n",
      "Iteration  4\n",
      "New weights are:  -780.2844  ,  -377.53699999999975\n",
      "98%  accuracy\n",
      "Iteration  5\n",
      "New weights are:  -767.2913  ,  -390.2453999999997\n",
      "98%  accuracy\n",
      "Iteration  6\n",
      "New weights are:  -754.2982  ,  -402.9537999999996\n",
      "98%  accuracy\n",
      "Iteration  7\n",
      "New weights are:  -743.4546999999999  ,  -411.5531999999995\n",
      "98%  accuracy\n",
      "Iteration  8\n",
      "New weights are:  -733.2549999999999  ,  -418.9667999999994\n",
      "98%  accuracy\n",
      "Iteration  9\n",
      "New weights are:  -725.8110999999999  ,  -421.4533999999993\n",
      "98%  accuracy\n",
      "Iteration  10\n",
      "New weights are:  -718.3671999999999  ,  -423.9399999999992\n",
      "98%  accuracy\n",
      "Iteration  11\n",
      "New weights are:  -710.9232999999999  ,  -426.4265999999991\n",
      "98%  accuracy\n",
      "Iteration  12\n",
      "New weights are:  -703.4793999999999  ,  -428.913199999999\n",
      "98%  accuracy\n",
      "Iteration  13\n",
      "New weights are:  -696.0355  ,  -431.3997999999989\n",
      "98%  accuracy\n",
      "Iteration  14\n",
      "New weights are:  -688.5916  ,  -433.8863999999988\n",
      "98%  accuracy\n",
      "Iteration  15\n",
      "New weights are:  -682.4881  ,  -434.23879999999866\n",
      "98%  accuracy\n",
      "Iteration  16\n",
      "New weights are:  -676.3846000000001  ,  -434.59119999999854\n",
      "98%  accuracy\n",
      "Iteration  17\n",
      "New weights are:  -670.2811000000002  ,  -434.9435999999984\n",
      "98%  accuracy\n",
      "Iteration  18\n",
      "New weights are:  -664.1776000000002  ,  -435.2959999999983\n",
      "98%  accuracy\n",
      "Iteration  19\n",
      "New weights are:  -658.0741000000003  ,  -435.64839999999816\n",
      "98%  accuracy\n",
      "Iteration  20\n",
      "New weights are:  -651.9706000000003  ,  -436.00079999999804\n",
      "98%  accuracy\n",
      "Iteration  21\n",
      "New weights are:  -645.8671000000004  ,  -436.3531999999979\n",
      "98%  accuracy\n",
      "Iteration  22\n",
      "New weights are:  -639.7636000000005  ,  -436.7055999999978\n",
      "98%  accuracy\n",
      "Iteration  23\n",
      "New weights are:  -633.6601000000005  ,  -437.05799999999766\n",
      "98%  accuracy\n",
      "Iteration  24\n",
      "New weights are:  -627.5566000000006  ,  -437.41039999999754\n",
      "98%  accuracy\n",
      "Iteration  25\n",
      "New weights are:  -625.6005000000006  ,  -431.7751999999974\n",
      "98%  accuracy\n",
      "Iteration  26\n",
      "New weights are:  -619.4970000000006  ,  -432.1275999999973\n",
      "98%  accuracy\n",
      "Iteration  27\n",
      "New weights are:  -617.5409000000006  ,  -426.4923999999972\n",
      "98%  accuracy\n",
      "Iteration  28\n",
      "New weights are:  -611.4374000000007  ,  -426.84479999999706\n",
      "98%  accuracy\n",
      "Iteration  29\n",
      "New weights are:  -609.4813000000007  ,  -421.20959999999695\n",
      "98%  accuracy\n",
      "Iteration  30\n",
      "New weights are:  -603.3778000000008  ,  -421.56199999999683\n",
      "98%  accuracy\n",
      "Iteration  31\n",
      "New weights are:  -601.4217000000008  ,  -415.9267999999967\n",
      "98%  accuracy\n",
      "Iteration  32\n",
      "New weights are:  -595.3182000000008  ,  -416.2791999999966\n",
      "98%  accuracy\n",
      "Iteration  33\n",
      "New weights are:  -593.3621000000009  ,  -410.6439999999965\n",
      "98%  accuracy\n",
      "Iteration  34\n",
      "New weights are:  -587.2586000000009  ,  -410.99639999999636\n",
      "98%  accuracy\n",
      "Iteration  35\n",
      "New weights are:  -585.3025000000009  ,  -405.36119999999624\n",
      "98%  accuracy\n",
      "Iteration  36\n",
      "New weights are:  -579.199000000001  ,  -405.7135999999961\n",
      "98%  accuracy\n",
      "Iteration  37\n",
      "New weights are:  -577.242900000001  ,  -400.078399999996\n",
      "98%  accuracy\n",
      "Iteration  38\n",
      "New weights are:  -571.139400000001  ,  -400.4307999999959\n",
      "98%  accuracy\n",
      "Iteration  39\n",
      "New weights are:  -569.183300000001  ,  -394.7955999999958\n",
      "98%  accuracy\n",
      "Iteration  40\n",
      "New weights are:  -567.2272000000011  ,  -389.16039999999566\n",
      "98%  accuracy\n",
      "Iteration  41\n",
      "New weights are:  -561.1237000000011  ,  -389.51279999999554\n",
      "98%  accuracy\n",
      "Iteration  42\n",
      "New weights are:  -559.1676000000011  ,  -383.8775999999954\n",
      "98%  accuracy\n",
      "Iteration  43\n",
      "New weights are:  -553.0641000000012  ,  -384.2299999999953\n",
      "98%  accuracy\n",
      "Iteration  44\n",
      "New weights are:  -551.1080000000012  ,  -378.5947999999952\n",
      "98%  accuracy\n",
      "Iteration  45\n",
      "New weights are:  -545.0045000000013  ,  -378.94719999999506\n",
      "98%  accuracy\n",
      "Iteration  46\n",
      "New weights are:  -543.0484000000013  ,  -373.31199999999495\n",
      "98%  accuracy\n",
      "Iteration  47\n",
      "New weights are:  -536.9449000000013  ,  -373.6643999999948\n",
      "98%  accuracy\n",
      "Iteration  48\n",
      "New weights are:  -534.9888000000013  ,  -368.0291999999947\n",
      "98%  accuracy\n",
      "Iteration  49\n",
      "New weights are:  -528.8853000000014  ,  -368.3815999999946\n",
      "98%  accuracy\n",
      "Iteration  50\n",
      "New weights are:  -526.9292000000014  ,  -362.7463999999945\n",
      "98%  accuracy\n",
      "Final percent accurate 0.98\n",
      "51  iterations total\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#set params and variables\n",
    "data['Bias'] = bias\n",
    "weight1 = weight1_input\n",
    "weight2 = weight2_input\n",
    "iteration_limit = 50\n",
    "iteration = 1\n",
    "accuracy = 0\n",
    "\n",
    "#desired response as numeric binary value\n",
    "data['d_response'] = 0.0\n",
    "data['d_response'] = np.where(data['y'] == 'a' , 1.0 , 0.0)\n",
    "data['d_response'] = np.where(data['y'] == 'b' , -1.0 , data['d_response'])\n",
    "\n",
    "#loop until limit criteria is met\n",
    "while iteration <= iteration_limit and accuracy <= 1:\n",
    "    print('Iteration ' , iteration)\n",
    "    #2 weight initialization\n",
    "    data['x1w'] = data['x1']*weight1\n",
    "    data['x2w'] = data['x2']*weight2\n",
    "\n",
    "    #activation\n",
    "    data['x'] = data['x1w'] + data['x2w'] + data['Bias']\n",
    "\n",
    "    #computation of actual repsonse\n",
    "    #using threshold function\n",
    "    data['sgn_response'] = np.sign(data['x'])\n",
    "\n",
    "    #calculate accuracy\n",
    "    accurate = 0\n",
    "    for i in range(len(data)):\n",
    "        if data['sgn_response'][i] == data['d_response'][i]:\n",
    "            accurate += 1\n",
    "\n",
    "    accuracy = ( accurate/len(data))\n",
    "    \n",
    "\n",
    "    #update weights\n",
    "    i = 0\n",
    "    for i in range(len(data)):\n",
    "        error = (data['d_response'][i]-data['sgn_response'][i])\n",
    "        weight1 += LearningRate*error*data['x1'][i]\n",
    "      \n",
    "    j = 0\n",
    "    for j in range(len(data)):\n",
    "        error = (data['d_response'][j]-data['sgn_response'][j])\n",
    "        weight2 += LearningRate*error*data['x2'][j]\n",
    "\n",
    "    print('New weights are: ', weight1 ,' , ' , weight2)\n",
    "    print( \"{:.0%}\".format(accuracy), ' accuracy')\n",
    "\n",
    "    iteration = iteration + 1\n",
    "\n",
    "print('Final percent accurate' , accuracy)\n",
    "print(iteration , ' iterations total')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing algorithm using sigmoid function instead of threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final percent accurate 0.978\n",
      "51  iterations total\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#set params and variables\n",
    "data['Bias'] = bias\n",
    "weight1 = weight1_input\n",
    "weight2 = weight2_input\n",
    "iteration_limit = 50\n",
    "iteration = 1\n",
    "accuracy = 0\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#desired response as numeric binary value\n",
    "data['d_response'] = 0.0\n",
    "data['d_response'] = np.where(data['y'] == 'a' , 1.0 , 0.0)\n",
    "data['d_response'] = np.where(data['y'] == 'b' , -1.0 , data['d_response'])\n",
    "\n",
    "#loop until limit criteria is met\n",
    "while iteration <= iteration_limit and accuracy <= 1:\n",
    "    #print('Iteration ' , iteration)\n",
    "    #2 weight initialization\n",
    "    data['x1w'] = data['x1']*weight1\n",
    "    data['x2w'] = data['x2']*weight2\n",
    "\n",
    "    #activation\n",
    "    data['x'] = data['x1w'] + data['x2w'] + data['Bias']\n",
    "\n",
    "    #computation of actual repsonse\n",
    "    #using sigmoid function - logistic\n",
    "    data['sgn_response'] = round(1/(1 +np.exp(-data['x'])),3)\n",
    "    \n",
    "    #sigmoid(data['x'])\n",
    "\n",
    "    #reformmat to match previous encoding for categories\n",
    "    data['sgn_response'] = np.where(data['sgn_response'] > .5 , 1.0 ,data['sgn_response'])\n",
    "    data['sgn_response'] = np.where(data['sgn_response'] <= .5 , -1.0 ,data['sgn_response'])\n",
    "\n",
    "    #calculate accuracy\n",
    "    accurate = 0\n",
    "    for i in range(len(data)):\n",
    "        if data['sgn_response'][i] == data['d_response'][i]:\n",
    "            accurate += 1\n",
    "\n",
    "    accuracy = ( accurate/len(data))\n",
    "    \n",
    "\n",
    "    #update weights\n",
    "    i = 0\n",
    "    for i in range(len(data)):\n",
    "        error = (data['d_response'][i]-data['sgn_response'][i])\n",
    "        weight1 += LearningRate*error*data['x1'][i]\n",
    "      \n",
    "    j = 0\n",
    "    for j in range(len(data)):\n",
    "        error = (data['d_response'][j]-data['sgn_response'][j])\n",
    "        weight2 += LearningRate*error*data['x2'][j] \n",
    "\n",
    "    #print('New weights are: ', weight1 ,' , ' , weight2)\n",
    "    #print( \"{:.0%}\".format(accuracy), ' accuracy')\n",
    "\n",
    "    iteration = iteration + 1\n",
    "\n",
    "print('Final percent accurate' , accuracy)\n",
    "print(iteration , ' iterations total')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "\n",
    "Looking at the output from the sigmoid function, the accuaracy is the same with the same amount of iterations/steps as for the threshold function. Thus there is no improvement by using a sigmoid function over a logistic one. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ff8cc86edce4682271839ab3bea16beed99f7e7a7be82a48fc82badb4054bc77"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
