{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NON-SEPARABLE CLASSIFICATION PROJECT â€“ MULTI-FONT CHARACTER RECOGNITION:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Megan Petralia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following scientific publication was used for reference:\n",
    "\n",
    "Font Recognition by a Neural Network\n",
    "\n",
    "Author Ming-Chih Lee , William J.B., Oldham\n",
    "\n",
    "https://www.sciencedirect.com/science/article/abs/pii/S0020737305801142\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages to use such as pandas for dataframe aggregation and manipulation as well matplotlib and seaborn for plotting. Tensorflow, keras for model building. Sklearn and bayes_opt for normalization and optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import io\n",
    "from bayes_opt import BayesianOptimization\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "## Importing more required libraries\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import warnings\n",
    "\n",
    "#makes numby printouts easier to read\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Known information about data used:\n",
    "\n",
    "The network will be trained on upper-case English letters in selected fonts. The data that will be used for this project, consisting of 6 fonts (Courier, New York, Chicago, Geneva, Times, and Venice), was collected and quantized by Lee (see reference linked above). A brief summary of the data collection method is presented here:\n",
    "1. The image of the letter is normalized to an 18 x 18 character matrix, where the line thickness is one and the image is represented by 0's (background) and 1's (foreground).\n",
    "2. Fourteen properties similar to those proposed by Fujii and Morita were extracted from each image. Each property is a 3 x 3 matrix, thus, for each image, a 14 x 9 matrix is generated. This is the X matrix for that image. A property recognition matrix, Y, is constructed for each image and is also a 14 x 9 matrix. It is chosen arbitrarily and is as simple as possible. W is a 9 x 9 filter matrix which maps X to Y and can be found from: W = X* Y, where X* the pseudo-inverse of X.\n",
    "3. A 3 x 3 window is moved from upper left to lower right over the character image. The 9 elements in the window are multiplied by the matrix W. If the output matches a row of Y, say row k, the kth place in the count matrix is incremented by the weighting factor of that property.\n",
    "Thus, the count matrix for a character contains the number of exact template matches, weighted by position. The result is 156 (26 x 6) 14-element vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alphabet training and testing datasets are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_train = (\"Alphabet_training.txt\")\n",
    "loc_test = (\"Alphabet_testing.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is reformatted into input/output train/test arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(loc_train, \"r\")\n",
    "string = f.read()\n",
    "array = np.fromstring(string, dtype=int, sep='\\n')\n",
    "split_array = np.array_split(array, 78)\n",
    "#split_array[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs have 14 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input_array = [item[0:14] for item in split_array]\n",
    "input_array = np.array(input_array)\n",
    "input_array[0].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at first 4 inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  8],\n",
       "       [ 7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 11],\n",
       "       [12, 10,  1,  1,  0,  0,  0,  4,  6,  0,  0,  0,  0,  2],\n",
       "       [21, 10,  4,  4,  0,  1,  1,  0,  5,  0,  2,  0,  0,  2]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_array[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outputs have 26 classes, for all 26 letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_array = [item[14:] for item in split_array]\n",
    "output_array = np.array(output_array)\n",
    "output_array[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at first 4 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_array[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(loc_test, \"r\")\n",
    "string = f.read()\n",
    "array = np.fromstring(string, dtype=int, sep='\\n')\n",
    "split_array = np.array_split(array, 78)\n",
    "#split_array[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test_array = [item[0:14] for item in split_array]\n",
    "input_test_array = np.array(input_array)\n",
    "#input_test_array[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_test_array = [item[14:] for item in split_array]\n",
    "output_test_array = np.array(output_test_array)\n",
    "#output_test_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization/Scaling:\n",
    "Normalization or scaling is not needed here. This procdure is provided with an even dataset of all different 26 letters in each of 3 fonts. With the letter image input/output , essentially already hot coded, the data is ready to be input into a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the Keras Model is defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The keras model defined includes 2 rectified linear functions, 1 drop out to prevent overfitting, and 1 sigmoid layer, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The specific layer values (shape , drop out rate , etc.) are decided by the bayesian optimizer below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining various initialization parameters for MLP model\n",
    "num_features = input_array.shape[1]\n",
    "num_classes = output_array.shape[1] \n",
    "\n",
    "# Let's create a helper function first which builds the model with various parameters.\n",
    "def get_model(input_dim, dense_0_neurons, dense_1_neurons, dropout_rate, num_classes):\n",
    "    # Builds a Sequential MLP model using Keras and returns it\n",
    "    \n",
    "    # Define the keras model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(dense_0_neurons, input_dim=input_dim, activation='relu', name=\"dense_1\"))\n",
    "    model.add(Dense(dense_1_neurons, activation='relu', name=\"dense_2\"))\n",
    "    model.add(Dropout(dropout_rate, name=\"dropout\"))\n",
    "    model.add(Dense(num_classes, activation='sigmoid', name=\"dense_3\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model takes 14 input features, and outputs 26 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Features:  14\n",
      "# Classes:  26\n"
     ]
    }
   ],
   "source": [
    "print('# Features: ' , num_features)\n",
    "print('# Classes: ' , num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the following functions are set up for the Bayesian Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The model is built for optimization using categorical cross entropy as the loss function, stochastic gradient descent for optimization, and accuracy as the performance metric. Batch size is 26, chosen becuase it's approximately 1/3 of the size of the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Because of the nature of the dataset, I decided not to take out part of the training dataset for validation. Cross-fold validation makes less sense, because there are only three records of each letter, of a differe font each, it seems more optimal to focus on accuracy compared to the test dataset and utilize on the training records for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bayesian Optimizer\n",
    "def fit_with(num_features, num_classes, verbose, dense_0_neurons_x20, dense_1_neurons_x26, dropout_rate):\n",
    "\n",
    "    # Calculate true hyperparameter values for discrete variables.\n",
    "    dense_0_neurons = max(int(dense_0_neurons_x20 * 20), 20)\n",
    "    dense_1_neurons = max(int(dense_1_neurons_x26 * 26), 26)\n",
    "  \n",
    "    # Create the model using a specified hyperparameters.\n",
    "    model = get_model(num_features, dense_0_neurons, dense_1_neurons, dropout_rate, num_classes)\n",
    "\n",
    "    # Compile the keras model for a specified number of epochs.\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Fit keras model\n",
    "    history = model.fit(input_array, output_array, \n",
    "                        epochs=5, \n",
    "                        batch_size=26, #3 batches for 78 length dataset\n",
    "                        validation_split = 0.00, \n",
    "                        verbose=verbose)\n",
    "\n",
    "    # Evaluate the model with the eval dataset.\n",
    "    score = model.evaluate(input_array, output_array,\n",
    "                                  batch_size=26, verbose=0)\n",
    "    print('Test loss:', score[0], '   Test accuracy:', score[1])\n",
    "\n",
    "    # Return the accuracy.\n",
    "    return score[1]\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "verbose = 1\n",
    "fit_with_partial = partial(fit_with, num_features, num_classes, verbose) # Handles fixed parameters during optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian Optimizer is run, with accuracy and loss output at each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | dense_... | dense_... | dropou... |\n",
      "-------------------------------------------------------------\n",
      "Epoch 1/5\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 4.2215 - accuracy: 0.0128\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 3.8679 - accuracy: 0.0513\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.5691 - accuracy: 0.0641\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.3302 - accuracy: 0.0641\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.1399 - accuracy: 0.1410\n",
      "Test loss: 3.014878273010254    Test accuracy: 0.19230769574642181\n",
      "Epoch 1/5\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4.1643 - accuracy: 0.0128\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.8700 - accuracy: 0.0385\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 3.6658 - accuracy: 0.0641\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 3.4968 - accuracy: 0.0897\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 3.3263 - accuracy: 0.1154\n",
      "Test loss: 3.2263238430023193    Test accuracy: 0.10256410390138626\n",
      "Epoch 1/5\n",
      "3/3 [==============================] - 1s 2ms/step - loss: 5.3653 - accuracy: 0.0385\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4.9835 - accuracy: 0.0385\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4.7038 - accuracy: 0.0385\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 4.3464 - accuracy: 0.0641\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4.1401 - accuracy: 0.0385\n",
      "Test loss: 3.800814151763916    Test accuracy: 0.05128205195069313\n",
      "Epoch 1/5\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.9000 - accuracy: 0.0513\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.3772 - accuracy: 0.1026\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.0505 - accuracy: 0.1154\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.8150 - accuracy: 0.2179\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.6379 - accuracy: 0.2564\n",
      "Test loss: 2.5153563022613525    Test accuracy: 0.28205129504203796\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.2821  \u001b[0m | \u001b[95m 2.467   \u001b[0m | \u001b[95m 3.584   \u001b[0m | \u001b[95m 0.0     \u001b[0m |\n",
      "Epoch 1/5\n",
      "3/3 [==============================] - 0s 980us/step - loss: 4.3890 - accuracy: 0.0385\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.6807 - accuracy: 0.0769\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.2449 - accuracy: 0.1282\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.9452 - accuracy: 0.1923\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.7474 - accuracy: 0.2436\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002B663697D90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Test loss: 2.618356704711914    Test accuracy: 0.28205129504203796\n",
      "Epoch 1/5\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 5.1556 - accuracy: 0.0385\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 4.3221 - accuracy: 0.0641\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.9283 - accuracy: 0.0385\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 3.7234 - accuracy: 0.0641\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 3.4168 - accuracy: 0.0897\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002B660541E18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Test loss: 2.9034955501556396    Test accuracy: 0.20512820780277252\n",
      "Epoch 1/5\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4.6922 - accuracy: 0.0641\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4.4507 - accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4.1238 - accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 3.6947 - accuracy: 0.0897\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.5110 - accuracy: 0.1154\n",
      "Test loss: 3.03466796875    Test accuracy: 0.12820513546466827\n",
      "Epoch 1/5\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 4.5647 - accuracy: 0.0513\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 4.0419 - accuracy: 0.0641\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 3.6396 - accuracy: 0.0769\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 3.3612 - accuracy: 0.1538\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 3.1426 - accuracy: 0.0897\n",
      "Test loss: 2.996406078338623    Test accuracy: 0.10256410390138626\n",
      "=============================================================\n",
      "Iteration 0: \n",
      "\t{'target': 0.19230769574642181, 'params': {'dense_0_neurons_x20': 2.2344704150482366, 'dense_1_neurons_x26': 3.2050383790149057, 'dropout_rate': 3.431244520346599e-05}}\n",
      "Iteration 1: \n",
      "\t{'target': 0.10256410390138626, 'params': {'dense_0_neurons_x20': 1.867464232421887, 'dense_1_neurons_x26': 1.3696188506147617, 'dropout_rate': 0.027701578430639338}}\n",
      "Iteration 2: \n",
      "\t{'target': 0.05128205195069313, 'params': {'dense_0_neurons_x20': 1.496032676408547, 'dense_1_neurons_x26': 2.0057943265377527, 'dropout_rate': 0.11903024226920098}}\n",
      "Iteration 3: \n",
      "\t{'target': 0.28205129504203796, 'params': {'dense_0_neurons_x20': 2.4674282621214614, 'dense_1_neurons_x26': 3.584222107697829, 'dropout_rate': 0.0}}\n",
      "Iteration 4: \n",
      "\t{'target': 0.28205129504203796, 'params': {'dense_0_neurons_x20': 2.9826344992892206, 'dense_1_neurons_x26': 4.1, 'dropout_rate': 0.0}}\n",
      "Iteration 5: \n",
      "\t{'target': 0.20512820780277252, 'params': {'dense_0_neurons_x20': 3.866282501640661, 'dense_1_neurons_x26': 3.2093844995321517, 'dropout_rate': 0.3}}\n",
      "Iteration 6: \n",
      "\t{'target': 0.12820513546466827, 'params': {'dense_0_neurons_x20': 1.9813285262869598, 'dense_1_neurons_x26': 4.1, 'dropout_rate': 0.3}}\n",
      "Iteration 7: \n",
      "\t{'target': 0.10256410390138626, 'params': {'dense_0_neurons_x20': 2.249315123810971, 'dense_1_neurons_x26': 3.227095635576439, 'dropout_rate': 0.011135850983025785}}\n",
      "{'target': 0.28205129504203796, 'params': {'dense_0_neurons_x20': 2.4674282621214614, 'dense_1_neurons_x26': 3.584222107697829, 'dropout_rate': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "# Bounded region of parameter space\n",
    "pbounds = {'dense_0_neurons_x20': (0.9, 4.1), 'dense_1_neurons_x26': (0.9, 4.1), 'dropout_rate': (0, 0.3)}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=fit_with_partial,\n",
    "    pbounds=pbounds,\n",
    "    verbose=1,  # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "optimizer.maximize(init_points=3, n_iter=5)\n",
    "\n",
    "for i, res in enumerate(optimizer.res):\n",
    "    print(\"Iteration {}: \\n\\t{}\".format(i, res))\n",
    "\n",
    "print(optimizer.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning with Hyper-parameter setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With the hyper-parameter tuning, we can see that the accuracy does go up - for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "3/3 - 0s - loss: 3.6829 - accuracy: 0.0769 - 297ms/epoch - 99ms/step\n",
      "Epoch 2/35\n",
      "3/3 - 0s - loss: 3.3143 - accuracy: 0.0897 - 5ms/epoch - 2ms/step\n",
      "Epoch 3/35\n",
      "3/3 - 0s - loss: 3.0633 - accuracy: 0.1154 - 6ms/epoch - 2ms/step\n",
      "Epoch 4/35\n",
      "3/3 - 0s - loss: 2.8862 - accuracy: 0.1538 - 5ms/epoch - 2ms/step\n",
      "Epoch 5/35\n",
      "3/3 - 0s - loss: 2.7351 - accuracy: 0.2564 - 8ms/epoch - 3ms/step\n",
      "Epoch 6/35\n",
      "3/3 - 0s - loss: 2.5933 - accuracy: 0.2308 - 5ms/epoch - 2ms/step\n",
      "Epoch 7/35\n",
      "3/3 - 0s - loss: 2.4724 - accuracy: 0.2564 - 8ms/epoch - 3ms/step\n",
      "Epoch 8/35\n",
      "3/3 - 0s - loss: 2.3499 - accuracy: 0.4103 - 6ms/epoch - 2ms/step\n",
      "Epoch 9/35\n",
      "3/3 - 0s - loss: 2.2339 - accuracy: 0.4615 - 7ms/epoch - 2ms/step\n",
      "Epoch 10/35\n",
      "3/3 - 0s - loss: 2.1264 - accuracy: 0.4872 - 5ms/epoch - 2ms/step\n",
      "Epoch 11/35\n",
      "3/3 - 0s - loss: 2.0287 - accuracy: 0.5513 - 5ms/epoch - 2ms/step\n",
      "Epoch 12/35\n",
      "3/3 - 0s - loss: 1.9278 - accuracy: 0.6282 - 4ms/epoch - 1ms/step\n",
      "Epoch 13/35\n",
      "3/3 - 0s - loss: 1.8400 - accuracy: 0.6667 - 5ms/epoch - 2ms/step\n",
      "Epoch 14/35\n",
      "3/3 - 0s - loss: 1.7527 - accuracy: 0.6923 - 6ms/epoch - 2ms/step\n",
      "Epoch 15/35\n",
      "3/3 - 0s - loss: 1.6721 - accuracy: 0.6667 - 4ms/epoch - 1ms/step\n",
      "Epoch 16/35\n",
      "3/3 - 0s - loss: 1.5931 - accuracy: 0.6795 - 7ms/epoch - 2ms/step\n",
      "Epoch 17/35\n",
      "3/3 - 0s - loss: 1.5195 - accuracy: 0.7308 - 3ms/epoch - 997us/step\n",
      "Epoch 18/35\n",
      "3/3 - 0s - loss: 1.4534 - accuracy: 0.7051 - 5ms/epoch - 2ms/step\n",
      "Epoch 19/35\n",
      "3/3 - 0s - loss: 1.3863 - accuracy: 0.7308 - 4ms/epoch - 1ms/step\n",
      "Epoch 20/35\n",
      "3/3 - 0s - loss: 1.3202 - accuracy: 0.7308 - 4ms/epoch - 1ms/step\n",
      "Epoch 21/35\n",
      "3/3 - 0s - loss: 1.2601 - accuracy: 0.7436 - 6ms/epoch - 2ms/step\n",
      "Epoch 22/35\n",
      "3/3 - 0s - loss: 1.2021 - accuracy: 0.7564 - 6ms/epoch - 2ms/step\n",
      "Epoch 23/35\n",
      "3/3 - 0s - loss: 1.1458 - accuracy: 0.7821 - 8ms/epoch - 3ms/step\n",
      "Epoch 24/35\n",
      "3/3 - 0s - loss: 1.0957 - accuracy: 0.8077 - 5ms/epoch - 2ms/step\n",
      "Epoch 25/35\n",
      "3/3 - 0s - loss: 1.0442 - accuracy: 0.7949 - 6ms/epoch - 2ms/step\n",
      "Epoch 26/35\n",
      "3/3 - 0s - loss: 0.9982 - accuracy: 0.7949 - 6ms/epoch - 2ms/step\n",
      "Epoch 27/35\n",
      "3/3 - 0s - loss: 0.9574 - accuracy: 0.7949 - 8ms/epoch - 3ms/step\n",
      "Epoch 28/35\n",
      "3/3 - 0s - loss: 0.9117 - accuracy: 0.8333 - 5ms/epoch - 2ms/step\n",
      "Epoch 29/35\n",
      "3/3 - 0s - loss: 0.8706 - accuracy: 0.8718 - 7ms/epoch - 2ms/step\n",
      "Epoch 30/35\n",
      "3/3 - 0s - loss: 0.8298 - accuracy: 0.8718 - 4ms/epoch - 1ms/step\n",
      "Epoch 31/35\n",
      "3/3 - 0s - loss: 0.7938 - accuracy: 0.8846 - 6ms/epoch - 2ms/step\n",
      "Epoch 32/35\n",
      "3/3 - 0s - loss: 0.7593 - accuracy: 0.8846 - 5ms/epoch - 2ms/step\n",
      "Epoch 33/35\n",
      "3/3 - 0s - loss: 0.7257 - accuracy: 0.9103 - 4ms/epoch - 1ms/step\n",
      "Epoch 34/35\n",
      "3/3 - 0s - loss: 0.6968 - accuracy: 0.8974 - 4ms/epoch - 1ms/step\n",
      "Epoch 35/35\n",
      "3/3 - 0s - loss: 0.6673 - accuracy: 0.9359 - 3ms/epoch - 997us/step\n",
      "Test loss: 0.6436604261398315    Test accuracy: 0.9358974099159241\n"
     ]
    }
   ],
   "source": [
    "# Create the model using a specified hyperparameters.\n",
    "dense_0_neurons=2.47*20; dense_1_neurons=3.58*26; dropout_rate=0.0 #hyper-parameters found above are used as 3.8 and 3.53\n",
    "model = get_model(num_features, dense_0_neurons, dense_1_neurons, dropout_rate, num_classes)\n",
    "\n",
    "# Compile the keras model for a specified number of epochs.\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Fit keras model\n",
    "history = model.fit(input_array, output_array, epochs=35, batch_size=26, \n",
    "                        validation_split = 0.00, verbose=2)\n",
    "\n",
    "# Evaluate the model with the eval dataset.\n",
    "score = model.evaluate(input_test_array, output_test_array,\n",
    "                                  batch_size=26, verbose=0)\n",
    "print('Test loss:', score[0], '   Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Looking at the output, we can see that the model creates an approximate 94% accuracy against the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for plotting history\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_metrics(history):\n",
    "  metrics =  ['loss', 'accuracy']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(1,2,n+1)\n",
    "    plt.tight_layout()\n",
    "    plt.plot(history.epoch,  history.history[metric], color=colors[0], label='Train')\n",
    "    #plt.plot(history.epoch, history.history['val_'+metric],\n",
    "    #         color=colors[0], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training/validation history of our Keras model\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "plot_metrics(history)\n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The above charts above show the loss getting lower and the accuracy getting better per epoch. The accuracy increases less with a flatter slope around epoch 30, indicated the right number of epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions):\n",
    "  cm = confusion_matrix(labels, predictions)\n",
    "  plt.figure(figsize=(8,8))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion Matrix')\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make output predictions using test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions\n",
    "y_test_predictions = (model.predict(input_test_array, batch_size = 26) > 0.5).astype(\"int32\")\n",
    "#y_test_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare predicted test output against actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.6436604261398315\n",
      "accuracy :  0.9358974099159241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create Confusion matrix\n",
    "#y_test_predictions = model.predict_classes(input_test_array, batch_size=26)\n",
    "y_test_predictions = (model.predict(input_test_array, batch_size = 26) > 0.5).astype(\"int32\")\n",
    "baseline_results = model.evaluate(input_test_array, output_test_array,\n",
    "                                  batch_size=26, verbose=0)\n",
    "\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "#plot_cm(output_test_array, y_test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The model performs well on the test data well, with 84% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: dnn_model_CharRecognition\\assets\n"
     ]
    }
   ],
   "source": [
    "#save final model to reload in the future\n",
    "model.save('dnn_model_CharRecognition')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0a05dd1933bc8de4c723981543747ad9357c4f2aac8c21722741f65705e4fc32"
  },
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
